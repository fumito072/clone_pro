"""
WSLç”¨ã®æ–°è¦è©±è€…ãƒ‡ãƒ¼ã‚¿æº–å‚™ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

macOSã‹ã‚‰é€ä¿¡ã•ã‚ŒãŸéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†ã—ã€
LoRAãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’æº–å‚™ã—ã¾ã™ã€‚

ä½¿ã„æ–¹:
    python3 prepare_speaker_wsl.py --audio ~/narisawa_voice.wav --speaker narisawa
"""

import argparse
import subprocess
from pathlib import Path
import torchaudio
import torch
from tqdm import tqdm
import os
from google.cloud import speech_v1p1beta1 as speech
import time


def check_dependencies():
    """å¿…è¦ãªä¾å­˜é–¢ä¿‚ã‚’ãƒã‚§ãƒƒã‚¯"""
    print("ğŸ” ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯ä¸­...")
    
    # ffmpegãƒã‚§ãƒƒã‚¯
    try:
        subprocess.run(['ffmpeg', '-version'], capture_output=True, check=True)
        print("âœ… ffmpeg: ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«æ¸ˆã¿")
    except (subprocess.CalledProcessError, FileNotFoundError):
        print("âŒ ffmpeg: æœªã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«")
        print("ğŸ’¡ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: sudo apt-get install ffmpeg")
        return False
    
    # Google Cloudèªè¨¼ãƒã‚§ãƒƒã‚¯
    try:
        client = speech.SpeechClient()
        print("âœ… Google Cloudèªè¨¼: OK")
    except Exception as e:
        print(f"âš ï¸  Google Cloudèªè¨¼: {e}")
        print("ğŸ’¡ èªè¨¼è¨­å®š: export GOOGLE_APPLICATION_CREDENTIALS=/path/to/key.json")
    
    # PyTorchã¨torchaudioãƒã‚§ãƒƒã‚¯
    try:
        import torch
        import torchaudio
        print(f"âœ… PyTorch: {torch.__version__}")
        print(f"âœ… torchaudio: {torchaudio.__version__}")
    except ImportError as e:
        print(f"âŒ PyTorch/torchaudio: {e}")
        return False
    
    return True


def convert_to_wav(input_file, output_file, target_sr=24000):
    """
    éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’WAVå½¢å¼ã«å¤‰æ›ï¼ˆ24kHz, ãƒ¢ãƒãƒ©ãƒ«ï¼‰
    """
    print(f"\nğŸ”„ WAVå¤‰æ›ä¸­: {input_file.name}")
    
    try:
        cmd = [
            'ffmpeg',
            '-i', str(input_file),
            '-ar', str(target_sr),
            '-ac', '1',
            '-c:a', 'pcm_s16le',
            '-y',
            str(output_file)
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode == 0:
            print(f"âœ… WAVå¤‰æ›å®Œäº†: {output_file}")
            return True
        else:
            print(f"âŒ å¤‰æ›å¤±æ•—: {result.stderr}")
            return False
    
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}")
        return False


def split_audio_into_segments(audio_file, output_dir, speaker_name, segment_length=10.0, sample_rate=24000):
    """
    éŸ³å£°ã‚’å›ºå®šé•·ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«åˆ†å‰²
    
    Args:
        audio_file: å…¥åŠ›éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«
        output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        speaker_name: è©±è€…å
        segment_length: ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé•·ï¼ˆç§’ï¼‰
        sample_rate: ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆ
    
    Returns:
        ç”Ÿæˆã•ã‚ŒãŸã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°
    """
    print(f"\nâœ‚ï¸  éŸ³å£°ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†å‰²ä¸­...")
    
    # éŸ³å£°èª­ã¿è¾¼ã¿
    waveform, sr = torchaudio.load(str(audio_file))
    
    # ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    if sr != sample_rate:
        resampler = torchaudio.transforms.Resample(sr, sample_rate)
        waveform = resampler(waveform)
        sr = sample_rate
    
    # ãƒ¢ãƒãƒ©ãƒ«å¤‰æ›
    if waveform.shape[0] > 1:
        waveform = torch.mean(waveform, dim=0, keepdim=True)
    
    total_duration = waveform.shape[1] / sr
    segment_samples = int(segment_length * sr)
    
    print(f"   ç·éŸ³å£°é•·: {total_duration:.1f}ç§’")
    print(f"   ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé•·: {segment_length}ç§’")
    
    output_dir.mkdir(parents=True, exist_ok=True)
    
    segment_count = 0
    for start_sample in range(0, waveform.shape[1], segment_samples):
        end_sample = min(start_sample + segment_samples, waveform.shape[1])
        segment = waveform[:, start_sample:end_sample]
        
        # çŸ­ã™ãã‚‹ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼ˆ2ç§’æœªæº€ï¼‰
        if segment.shape[1] < sr * 2:
            continue
        
        output_path = output_dir / f"{speaker_name}_segment_{segment_count:04d}.wav"
        torchaudio.save(str(output_path), segment, sr)
        segment_count += 1
    
    print(f"âœ… ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†å‰²å®Œäº†: {segment_count}ãƒ•ã‚¡ã‚¤ãƒ«")
    return segment_count


def transcribe_with_google_cloud(segments_dir, speaker_name, output_file):
    """
    Google Cloud Speech-to-Textã§æ–‡å­—èµ·ã“ã—
    
    Args:
        segments_dir: ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        speaker_name: è©±è€…å
        output_file: å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆtextï¼‰
    
    Returns:
        æˆåŠŸã—ãŸã‚‰True
    """
    print(f"\nğŸ“ Google Cloudæ–‡å­—èµ·ã“ã—é–‹å§‹...")
    
    segment_files = sorted(list(segments_dir.glob(f"{speaker_name}_segment_*.wav")))
    
    if len(segment_files) == 0:
        print("âŒ ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return False
    
    # Google Cloudèªè¨¼ç¢ºèª
    try:
        client = speech.SpeechClient()
        print("âœ… Google Cloudèªè¨¼æˆåŠŸ")
    except Exception as e:
        print(f"âŒ èªè¨¼å¤±æ•—: {e}")
        print("ğŸ’¡ GOOGLE_APPLICATION_CREDENTIALSã‚’è¨­å®šã—ã¦ãã ã•ã„")
        return False
    
    transcriptions = []
    
    for audio_file in tqdm(segment_files, desc="æ–‡å­—èµ·ã“ã—"):
        utt_id = audio_file.stem
        
        # éŸ³å£°èª­ã¿è¾¼ã¿
        with open(audio_file, "rb") as f:
            content = f.read()
        
        audio = speech.RecognitionAudio(content=content)
        config = speech.RecognitionConfig(
            encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
            sample_rate_hertz=24000,
            language_code="ja-JP",
            enable_automatic_punctuation=True,
            model="latest_long",
            use_enhanced=True,
        )
        
        try:
            response = client.recognize(config=config, audio=audio)
            
            transcript = ""
            for result in response.results:
                transcript += result.alternatives[0].transcript
            
            if transcript.strip():
                transcriptions.append({
                    "utt_id": utt_id,
                    "text": transcript.strip()
                })
        
        except Exception as e:
            print(f"\nâš ï¸  {audio_file.name}: {e}")
        
        time.sleep(0.1)  # APIåˆ¶é™å¯¾ç­–
    
    # textãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
    with open(output_file, "w", encoding="utf-8") as f:
        for item in transcriptions:
            f.write(f"{item['utt_id']} {item['text']}\n")
    
    print(f"\nâœ… æ–‡å­—èµ·ã“ã—å®Œäº†: {len(transcriptions)}è¡Œ")
    return True


def create_metadata_files(lora_dir, speaker_name):
    """
    LoRAãƒˆãƒ¬ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆ
    - wav.scp: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ãƒªã‚¹ãƒˆ
    - utt2spk: ç™ºè©±â†’è©±è€…ãƒãƒƒãƒ”ãƒ³ã‚°
    - spk2utt: è©±è€…â†’ç™ºè©±ãƒªã‚¹ãƒˆ
    
    Args:
        lora_dir: LoRAãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        speaker_name: è©±è€…å
    """
    print(f"\nğŸ“„ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆä¸­...")
    
    segments_dir = lora_dir / "segments"
    segment_files = sorted(list(segments_dir.glob(f"{speaker_name}_segment_*.wav")))
    
    # wav.scp
    wav_scp = lora_dir / "wav.scp"
    with open(wav_scp, "w") as f:
        for audio_file in segment_files:
            f.write(f"{audio_file.stem} {audio_file.absolute()}\n")
    print(f"âœ… wav.scp: {len(segment_files)}è¡Œ")
    
    # utt2spk
    utt2spk = lora_dir / "utt2spk"
    with open(utt2spk, "w") as f:
        for audio_file in segment_files:
            f.write(f"{audio_file.stem} {speaker_name}\n")
    print(f"âœ… utt2spk: {len(segment_files)}è¡Œ")
    
    # spk2utt
    spk2utt = lora_dir / "spk2utt"
    with open(spk2utt, "w") as f:
        utt_ids = [audio_file.stem for audio_file in segment_files]
        f.write(f"{speaker_name} {' '.join(utt_ids)}\n")
    print(f"âœ… spk2utt: 1è¡Œ")


def prepare_speaker_data_wsl(audio_file_path, speaker_name, segment_length=10.0):
    """
    WSLç”¨ã®æ–°è¦è©±è€…ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆãƒ¡ã‚¤ãƒ³å‡¦ç†ï¼‰
    
    Args:
        audio_file_path: å…¥åŠ›éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«
        speaker_name: è©±è€…å
        segment_length: ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé•·ï¼ˆç§’ï¼‰
    
    Returns:
        æˆåŠŸã—ãŸã‚‰True
    """
    print("\n" + "="*70)
    print(f"ğŸ¯ æ–°è¦è©±è€…ãƒ‡ãƒ¼ã‚¿æº–å‚™: {speaker_name}")
    print("="*70)
    
    # ä¾å­˜é–¢ä¿‚ãƒã‚§ãƒƒã‚¯
    if not check_dependencies():
        print("\nâŒ ä¾å­˜é–¢ä¿‚ã‚¨ãƒ©ãƒ¼ã€‚å¿…è¦ãªãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã‚’ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚")
        return False
    
    base_dir = Path(__file__).parent
    audio_file = Path(audio_file_path).expanduser()
    
    if not audio_file.exists():
        print(f"âŒ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {audio_file}")
        return False
    
    # LoRAãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    lora_dir = base_dir / f"lora_{speaker_name}"
    lora_dir.mkdir(exist_ok=True)
    
    segments_dir = lora_dir / "segments"
    
    # WAVå¤‰æ›
    wav_file = lora_dir / f"{speaker_name}_source.wav"
    if audio_file.suffix.lower() != '.wav':
        if not convert_to_wav(audio_file, wav_file):
            return False
    else:
        # ã™ã§ã«WAVå½¢å¼ã®å ´åˆã¯ã‚³ãƒ”ãƒ¼
        import shutil
        shutil.copy2(audio_file, wav_file)
        print(f"âœ… éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚³ãƒ”ãƒ¼: {wav_file}")
    
    # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†å‰²
    segment_count = split_audio_into_segments(
        wav_file,
        segments_dir,
        speaker_name,
        segment_length=segment_length
    )
    
    if segment_count == 0:
        print("âŒ ã‚»ã‚°ãƒ¡ãƒ³ãƒˆç”Ÿæˆå¤±æ•—")
        return False
    
    # Google Cloudæ–‡å­—èµ·ã“ã—
    text_file = lora_dir / "text"
    transcribe_success = transcribe_with_google_cloud(segments_dir, speaker_name, text_file)
    
    if not transcribe_success:
        print("âš ï¸  æ–‡å­—èµ·ã“ã—å¤±æ•—ï¼ˆæ‰‹å‹•ã§textãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¦ãã ã•ã„ï¼‰")
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    create_metadata_files(lora_dir, speaker_name)
    
    # ã‚µãƒãƒªãƒ¼
    print("\n" + "="*70)
    print("âœ… ãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº†ï¼")
    print("="*70)
    
    print(f"\nğŸ“¦ ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«:")
    print(f"   {lora_dir}/")
    print(f"   â”œâ”€â”€ segments/  ({segment_count}ãƒ•ã‚¡ã‚¤ãƒ«)")
    print(f"   â”œâ”€â”€ text")
    print(f"   â”œâ”€â”€ wav.scp")
    print(f"   â”œâ”€â”€ utt2spk")
    print(f"   â””â”€â”€ spk2utt")
    
    # æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—
    print(f"\nğŸ¯ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print(f"\n1. ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰LoRAãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°:")
    print(f"   # Google Cloud VMä¸Šã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°")
    print(f"   # ã¾ãŸã¯ã€ã‚¼ãƒ­ã‚·ãƒ§ãƒƒãƒˆéŸ³å£°åˆæˆã®ã¿ã§ä½¿ç”¨å¯èƒ½")
    
    print(f"\n2. å‚ç…§éŸ³å£°ã‚’æº–å‚™:")
    print(f"   # çŸ­ã„å‚ç…§éŸ³å£°ï¼ˆ3-10ç§’ç¨‹åº¦ï¼‰ã‚’ç”¨æ„")
    print(f"   # ä¾‹: {speaker_name}_reference.wav")
    
    print(f"\n3. è©±è€…ã‚’ç™»éŒ²:")
    print(f"   cd {base_dir}")
    print(f"   python3 speaker_cli.py add {speaker_name} \\")
    print(f"       {lora_dir}/segments/{speaker_name}_segment_0000.wav \\")
    print(f"       --prompt-text 'è©±è€…ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ã‚­ã‚¹ãƒˆ'")
    
    print(f"\n4. ã‚¢ã‚¯ãƒ†ã‚£ãƒ–åŒ–:")
    print(f"   python3 speaker_cli.py set {speaker_name}")
    
    print("\n" + "="*70)
    
    return True


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="WSLç”¨ã®æ–°è¦è©±è€…ãƒ‡ãƒ¼ã‚¿æº–å‚™")
    parser.add_argument("--audio", type=str, required=True, help="éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ï¼ˆä¾‹: ~/narisawa_voice.wavï¼‰")
    parser.add_argument("--speaker", type=str, required=True, help="è©±è€…åï¼ˆä¾‹: narisawaï¼‰")
    parser.add_argument("--segment-length", type=float, default=10.0, help="ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé•·ï¼ˆç§’ï¼‰")
    
    args = parser.parse_args()
    
    # Google Cloud Projectè¨­å®š
    if "GOOGLE_CLOUD_PROJECT" not in os.environ:
        os.environ["GOOGLE_CLOUD_PROJECT"] = "president-clone-1762149165"
    
    prepare_speaker_data_wsl(args.audio, args.speaker, args.segment_length)
