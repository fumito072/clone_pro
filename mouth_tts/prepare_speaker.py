"""
æ–°è¦è©±è€…ã®éŸ³å£°ãƒ‡ãƒ¼ã‚¿æº–å‚™ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

M4A/MP3ãªã©ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’WAVã«å¤‰æ›ã—ã€
ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†å‰²ã€Google Cloudæ–‡å­—èµ·ã“ã—ã€
ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆã¾ã§ä¸€æ‹¬ã§å®Ÿè¡Œã—ã¾ã™ã€‚
"""

import argparse
import subprocess
from pathlib import Path
import torchaudio
import torch
from tqdm import tqdm
import os
from google.cloud import speech_v1p1beta1 as speech
import time


def convert_to_wav(input_file, output_file, target_sr=24000):
    """
    éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’WAVå½¢å¼ã«å¤‰æ›
    """
    print(f"\nğŸ”„ WAVå¤‰æ›ä¸­: {input_file.name}")
    
    try:
        # ffmpegã§å¤‰æ›
        cmd = [
            'ffmpeg',
            '-i', str(input_file),
            '-ar', str(target_sr),
            '-ac', '1',
            '-c:a', 'pcm_s16le',
            '-y',
            str(output_file)
        ]
        
        result = subprocess.run(cmd, capture_output=True, text=True)
        
        if result.returncode == 0:
            print(f"âœ… WAVå¤‰æ›å®Œäº†: {output_file}")
            return True
        else:
            print(f"âŒ å¤‰æ›å¤±æ•—: {result.stderr}")
            return False
    
    except FileNotFoundError:
        print("âŒ ffmpegãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        print("ğŸ’¡ ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«: brew install ffmpeg")
        return False


def split_audio_into_segments(audio_file, output_dir, speaker_name, segment_length=10.0, sample_rate=24000):
    """
    éŸ³å£°ã‚’å›ºå®šé•·ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«åˆ†å‰²
    """
    print(f"\nâœ‚ï¸  éŸ³å£°ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†å‰²ä¸­...")
    
    # éŸ³å£°èª­ã¿è¾¼ã¿
    waveform, sr = torchaudio.load(str(audio_file))
    
    # ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆç¢ºèª
    if sr != sample_rate:
        resampler = torchaudio.transforms.Resample(sr, sample_rate)
        waveform = resampler(waveform)
        sr = sample_rate
    
    # ãƒ¢ãƒãƒ©ãƒ«å¤‰æ›
    if waveform.shape[0] > 1:
        waveform = torch.mean(waveform, dim=0, keepdim=True)
    
    total_duration = waveform.shape[1] / sr
    segment_samples = int(segment_length * sr)
    
    print(f"   ç·éŸ³å£°é•·: {total_duration:.1f}ç§’")
    print(f"   ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé•·: {segment_length}ç§’")
    
    output_dir.mkdir(parents=True, exist_ok=True)
    
    segment_count = 0
    for start_sample in range(0, waveform.shape[1], segment_samples):
        end_sample = min(start_sample + segment_samples, waveform.shape[1])
        segment = waveform[:, start_sample:end_sample]
        
        # çŸ­ã™ãã‚‹ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã¯ã‚¹ã‚­ãƒƒãƒ—
        if segment.shape[1] < sr * 2:  # 2ç§’æœªæº€
            continue
        
        output_path = output_dir / f"{speaker_name}_segment_{segment_count:04d}.wav"
        torchaudio.save(str(output_path), segment, sr)
        segment_count += 1
    
    print(f"âœ… ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†å‰²å®Œäº†: {segment_count}ãƒ•ã‚¡ã‚¤ãƒ«")
    return segment_count


def transcribe_with_google_cloud(segments_dir, speaker_name, output_file):
    """
    Google Cloud Speech-to-Textã§æ–‡å­—èµ·ã“ã—
    """
    print(f"\nğŸ“ Google Cloudæ–‡å­—èµ·ã“ã—é–‹å§‹...")
    
    segment_files = sorted(list(segments_dir.glob(f"{speaker_name}_segment_*.wav")))
    
    if len(segment_files) == 0:
        print("âŒ ã‚»ã‚°ãƒ¡ãƒ³ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return False
    
    # Google Cloudèªè¨¼ç¢ºèª
    try:
        client = speech.SpeechClient()
        print("âœ… Google Cloudèªè¨¼æˆåŠŸ")
    except Exception as e:
        print(f"âŒ èªè¨¼å¤±æ•—: {e}")
        return False
    
    transcriptions = []
    
    for audio_file in tqdm(segment_files, desc="æ–‡å­—èµ·ã“ã—"):
        utt_id = audio_file.stem
        
        # éŸ³å£°èª­ã¿è¾¼ã¿
        with open(audio_file, "rb") as f:
            content = f.read()
        
        audio = speech.RecognitionAudio(content=content)
        config = speech.RecognitionConfig(
            encoding=speech.RecognitionConfig.AudioEncoding.LINEAR16,
            sample_rate_hertz=24000,
            language_code="ja-JP",
            enable_automatic_punctuation=True,
            model="latest_long",
            use_enhanced=True,
        )
        
        try:
            response = client.recognize(config=config, audio=audio)
            
            transcript = ""
            for result in response.results:
                transcript += result.alternatives[0].transcript
            
            if transcript.strip():
                transcriptions.append({
                    "utt_id": utt_id,
                    "text": transcript.strip()
                })
        
        except Exception as e:
            print(f"\nâš ï¸  {audio_file.name}: {e}")
        
        time.sleep(0.1)  # APIåˆ¶é™å¯¾ç­–
    
    # textãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›
    with open(output_file, "w", encoding="utf-8") as f:
        for item in transcriptions:
            f.write(f"{item['utt_id']} {item['text']}\n")
    
    print(f"\nâœ… æ–‡å­—èµ·ã“ã—å®Œäº†: {len(transcriptions)}è¡Œ")
    return True


def create_metadata_files(lora_dir, speaker_name):
    """
    ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆï¼ˆwav.scp, utt2spk, spk2uttï¼‰
    """
    print(f"\nğŸ“„ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆä¸­...")
    
    segments_dir = lora_dir / "segments"
    segment_files = sorted(list(segments_dir.glob(f"{speaker_name}_segment_*.wav")))
    
    # wav.scp
    wav_scp = lora_dir / "wav.scp"
    with open(wav_scp, "w") as f:
        for audio_file in segment_files:
            f.write(f"{audio_file.stem} {audio_file.absolute()}\n")
    print(f"âœ… wav.scp: {len(segment_files)}è¡Œ")
    
    # utt2spk
    utt2spk = lora_dir / "utt2spk"
    with open(utt2spk, "w") as f:
        for audio_file in segment_files:
            f.write(f"{audio_file.stem} {speaker_name}\n")
    print(f"âœ… utt2spk: {len(segment_files)}è¡Œ")
    
    # spk2utt
    spk2utt = lora_dir / "spk2utt"
    with open(spk2utt, "w") as f:
        utt_ids = [audio_file.stem for audio_file in segment_files]
        f.write(f"{speaker_name} {' '.join(utt_ids)}\n")
    print(f"âœ… spk2utt: 1è¡Œ")
    
    # GCPç”¨ãƒ‘ã‚¹ç½®æ›ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
    replace_script = lora_dir / "replace_paths_for_gcp.sh"
    with open(replace_script, "w") as f:
        f.write(f"""#!/bin/bash
LORA_DIR="$HOME/lora_{speaker_name}"
sed -i.bak "s|{lora_dir}|${{LORA_DIR}}|g" ${{LORA_DIR}}/wav.scp
echo "âœ… ãƒ‘ã‚¹ç½®æ›å®Œäº†"
""")
    replace_script.chmod(0o755)
    print(f"âœ… GCPç”¨ãƒ‘ã‚¹ç½®æ›ã‚¹ã‚¯ãƒªãƒ—ãƒˆç”Ÿæˆ")


def prepare_speaker_data(audio_file_path, speaker_name):
    """
    æ–°è¦è©±è€…ãƒ‡ãƒ¼ã‚¿ã®å®Œå…¨æº–å‚™
    """
    print("\n" + "="*70)
    print(f"ğŸ¯ æ–°è¦è©±è€…ãƒ‡ãƒ¼ã‚¿æº–å‚™: {speaker_name}")
    print("="*70)
    
    base_dir = Path(__file__).parent
    audio_file = Path(audio_file_path)
    
    if not audio_file.exists():
        print(f"âŒ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {audio_file}")
        return False
    
    # LoRAãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
    lora_dir = base_dir / f"lora_{speaker_name}"
    lora_dir.mkdir(exist_ok=True)
    
    segments_dir = lora_dir / "segments"
    
    # WAVå¤‰æ›
    wav_file = lora_dir / f"{speaker_name}_source.wav"
    if audio_file.suffix.lower() != '.wav':
        if not convert_to_wav(audio_file, wav_file):
            return False
    else:
        wav_file = audio_file
    
    # ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåˆ†å‰²
    segment_count = split_audio_into_segments(
        wav_file,
        segments_dir,
        speaker_name,
        segment_length=10.0
    )
    
    if segment_count == 0:
        print("âŒ ã‚»ã‚°ãƒ¡ãƒ³ãƒˆç”Ÿæˆå¤±æ•—")
        return False
    
    # Google Cloudæ–‡å­—èµ·ã“ã—
    text_file = lora_dir / "text"
    if not transcribe_with_google_cloud(segments_dir, speaker_name, text_file):
        print("âš ï¸  æ–‡å­—èµ·ã“ã—å¤±æ•—ï¼ˆã‚¹ã‚­ãƒƒãƒ—å¯èƒ½ï¼‰")
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    create_metadata_files(lora_dir, speaker_name)
    
    # ã‚µãƒãƒªãƒ¼
    print("\n" + "="*70)
    print("âœ… ãƒ‡ãƒ¼ã‚¿æº–å‚™å®Œäº†ï¼")
    print("="*70)
    
    print(f"\nğŸ“¦ ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«:")
    print(f"   {lora_dir}/")
    print(f"   â”œâ”€â”€ segments/  ({segment_count}ãƒ•ã‚¡ã‚¤ãƒ«)")
    print(f"   â”œâ”€â”€ text")
    print(f"   â”œâ”€â”€ wav.scp")
    print(f"   â”œâ”€â”€ utt2spk")
    print(f"   â””â”€â”€ spk2utt")
    
    # æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—
    print(f"\nğŸ¯ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
    print(f"\n1. ãƒ‡ãƒ¼ã‚¿ã‚’tar.gzã«ã¾ã¨ã‚ã‚‹:")
    print(f"   cd {base_dir}")
    print(f"   tar -czf lora_{speaker_name}.tar.gz lora_{speaker_name}/")
    
    print(f"\n2. Google Cloud VMã«ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰:")
    print(f"   gcloud compute scp lora_{speaker_name}.tar.gz cosyvoice-finetune:~/ --zone=us-central1-a")
    
    print(f"\n3. VMä¸Šã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°:")
    print(f"   bash gpu_finetune.sh")
    
    print("\n" + "="*70)
    
    return True


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="æ–°è¦è©±è€…ãƒ‡ãƒ¼ã‚¿æº–å‚™")
    parser.add_argument("--audio", type=str, required=True, help="éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹")
    parser.add_argument("--speaker", type=str, required=True, help="è©±è€…å")
    parser.add_argument("--segment-length", type=float, default=10.0, help="ã‚»ã‚°ãƒ¡ãƒ³ãƒˆé•·ï¼ˆç§’ï¼‰")
    
    args = parser.parse_args()
    
    # Google Cloud Projectè¨­å®š
    if "GOOGLE_CLOUD_PROJECT" not in os.environ:
        os.environ["GOOGLE_CLOUD_PROJECT"] = "president-clone-1762149165"
    
    prepare_speaker_data(args.audio, args.speaker)
