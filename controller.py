import asyncio
import os
import re
import sys
import json
import base64
import tempfile
import subprocess
import time        # å‹•ç”»å†ç”Ÿå¾…æ©Ÿç”¨
import websockets  # ã€Œè€³ã€(STT)ãƒ»ã€Œå£ã€(TTS) æ¥ç¶šç”¨
import httpx       # ã€Œé ­ã€(LLM) æ¥ç¶šç”¨
import pyaudio     # ã€Œå£ã€(TTS) ã®éŸ³å£°ã‚’å†ç”Ÿç”¨
import wave
import io
from datetime import datetime
from pathlib import Path

# --- Google Cloudèªè¨¼è¨­å®š ---
# Application Default Credentials (ADC) ã‚’ä½¿ç”¨ã™ã‚‹å ´åˆã¯ã€
# ä»¥ä¸‹ã®ã‚³ãƒ¡ãƒ³ãƒˆã‚’è§£é™¤ã—ã¦ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆIDã‚’è¨­å®š
# os.environ["GOOGLE_CLOUD_PROJECT"] = "hosipro"

# --- ã‚µãƒ¼ãƒãƒ¼ã®ã‚¢ãƒ‰ãƒ¬ã‚¹ï¼ˆç’°å¢ƒå¤‰æ•°ã§ä¸Šæ›¸ãå¯èƒ½ï¼‰ ---
EARS_STT_SERVER_URL = os.getenv("EARS_STT_SERVER_URL", "ws://127.0.0.1:8001/listen")
HEAD_LLM_SERVER_URL = os.getenv("HEAD_LLM_SERVER_URL", "http://127.0.0.1:8002/think")
# Linux WSLä¸Šã®CosyVoice TTSã‚µãƒ¼ãƒãƒ¼ï¼ˆTailscaleçµŒç”±ï¼‰
MOUTH_TTS_SERVER_URL = os.getenv("MOUTH_TTS_SERVER_URL", "ws://100.64.94.124:8002/tts")
# MediaPipeé¡”ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã‚µãƒ¼ãƒãƒ¼
FACE_SERVER_URL = os.getenv("FACE_SERVER_URL", "http://127.0.0.1:8003/generate")

# --- LoRAéŸ³å£°åˆæˆè¨­å®š ---
# narisawa LoRAãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ï¼ˆLinuxå´ã§è¨­å®šæ¸ˆã¿ï¼‰
# å‚ç…§éŸ³å£°ãƒ‘ã‚¹ã¯ä½¿ç”¨ã—ãªã„ï¼ˆLoRAãƒ¢ãƒ¼ãƒ‰ã§ã¯spk2embedding.ptã‚’ä½¿ç”¨ï¼‰
SPEAKER_ID = os.getenv("SPEAKER_ID", "narisawa")  # LoRAå­¦ç¿’ã—ãŸè©±è€…ID
PROMPT_TEXT = os.getenv("PROMPT_TEXT", "")  # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ã‚­ã‚¹ãƒˆï¼ˆLoRAãƒ¢ãƒ¼ãƒ‰ã§ã¯ä¸è¦ï¼‰

# --- éŸ³å£°å†ç”Ÿã®è¨­å®š ---
AUDIO_FORMAT = pyaudio.paInt16
CHANNELS = 1
RATE = 24000  # CosyVoiceã¯ 24kHz
CHUNK_SIZE = 1024  # å†ç”Ÿãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚º
OUTPUT_DIR = Path(__file__).resolve().parent

# ç’°å¢ƒå¤‰æ•°ã§å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚’åˆ¶å¾¡ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: ä¿å­˜ã—ãªã„ï¼‰
SAVE_MOUTH_OUTPUT = os.getenv("SAVE_MOUTH_OUTPUT", "false").lower() in ("1", "true", "yes")

# é¡”ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³è¨­å®š
# ãƒ­ãƒ¼ã‚«ãƒ«çµ±åˆï¼ˆearsâ†’llmâ†’mouthï¼‰ã§ã¯ face ã¯ã€Œç„¡ã„ã‚‚ã®ã€ã¨ã—ã¦æ‰±ã†ã®ãŒå®‰å…¨ãªã®ã§ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆç„¡åŠ¹
ENABLE_FACE_ANIMATION = os.getenv("ENABLE_FACE_ANIMATION", "false").lower() in ("1", "true", "yes")
FACE_IMAGE_PATH = Path(__file__).parent / "face_wav2lip" / "narisawa_face.jpg"

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ãªå†ç”Ÿã‚¹ãƒˆãƒªãƒ¼ãƒ 
try:
    p = pyaudio.PyAudio()
    audio_stream = p.open(format=AUDIO_FORMAT,
                          channels=CHANNELS,
                          rate=RATE,
                          output=True)
except Exception as e:
    print(f"ğŸ›‘ [Audio] PyAudioã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
    print("    ãƒã‚¤ã‚¯ã‚„ã‚¹ãƒ”ãƒ¼ã‚«ãƒ¼ãŒæ­£ã—ãæ¥ç¶šã•ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
    exit()

processing_lock: asyncio.Lock | None = None
SENTENCE_SPLIT_REGEX = re.compile(r"(.+?[ã€‚ï¼Ÿï¼!?]+)")


def save_audio_result(audio_bytes: bytes) -> Path | None:
    if not audio_bytes:
        return None
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
    output_path = OUTPUT_DIR / f"mouth_output_{timestamp}.wav"
    try:
        with wave.open(str(output_path), "wb") as wf:
            wf.setnchannels(CHANNELS)
            wf.setsampwidth(p.get_sample_size(AUDIO_FORMAT))
            wf.setframerate(RATE)
            wf.writeframes(audio_bytes)
    except Exception as exc:
        print(f"âš ï¸ [Mouth] éŸ³å£°ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {exc}")
        return None
    return output_path

def _split_sentences(buffer: str) -> tuple[list[str], str]:
    """
    ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ä¸­ã«æºœã‚ãŸãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰æ–‡æœ«ï¼ˆã€‚ï¼Ÿï¼!?ã®ã„ãšã‚Œã‹ï¼‰ã®æ–‡ã‚’å–ã‚Šå‡ºã—ã€
    æ®‹ã‚Šã®ãƒãƒƒãƒ•ã‚¡ã‚’è¿”ã™ã€‚
    """
    sentences: list[str] = []
    remainder_start = 0
    for match in SENTENCE_SPLIT_REGEX.finditer(buffer):
        sentence = match.group(1).strip()
        if sentence:
            sentences.append(sentence)
        remainder_start = match.end()

    remainder = buffer[remainder_start:]
    return sentences, remainder


async def _generate_face_animation(audio_path: Path) -> Path | None:
    """
    éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰é¡”ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³å‹•ç”»ã‚’ç”Ÿæˆ
    
    Args:
        audio_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        
    Returns:
        ç”Ÿæˆã•ã‚ŒãŸå‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ï¼ˆå¤±æ•—æ™‚ã¯Noneï¼‰
    """
    if not ENABLE_FACE_ANIMATION:
        return None
        
    if not FACE_IMAGE_PATH.exists():
        print(f"âš ï¸ [Face] é¡”ç”»åƒãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {FACE_IMAGE_PATH}")
        return None
    
    print(f"\nğŸ­ [Face] ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯å‹•ç”»ç”Ÿæˆä¸­...", flush=True)
    
    try:
        async with httpx.AsyncClient(timeout=120.0) as client:
            # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿
            with open(audio_path, "rb") as f:
                audio_data = f.read()
            
            # multipart/form-dataã§ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
            files = {
                "audio": ("audio.wav", audio_data, "audio/wav")
            }
            data = {
                "face_image": str(FACE_IMAGE_PATH)
            }
            
            response = await client.post(FACE_SERVER_URL, files=files, data=data)
            
            if response.status_code == 200:
                # å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
                output_path = OUTPUT_DIR / f"face_output_{timestamp}.mp4"
                
                with open(output_path, "wb") as f:
                    f.write(response.content)
                
                print(f"âœ… [Face] å‹•ç”»ç”Ÿæˆå®Œäº†: {output_path.name} ({len(response.content)/1024:.1f}KB)")
                return output_path
            else:
                print(f"ğŸ›‘ [Face] å‹•ç”»ç”Ÿæˆã‚¨ãƒ©ãƒ¼ (Status: {response.status_code})")
                print(f"     è©³ç´°: {response.text[:200]}")
                return None
                
    except httpx.ConnectError:
        print(f"ğŸ›‘ [Face] Faceã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“ ({FACE_SERVER_URL})")
        print(f"ğŸ’¡ ç¢ºèª: Faceã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹")
        return None
    except httpx.TimeoutException:
        print(f"ğŸ›‘ [Face] ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆï¼ˆå‹•ç”»ç”Ÿæˆã«æ™‚é–“ãŒã‹ã‹ã‚Šã™ãã¦ã„ã¾ã™ï¼‰")
        return None
    except Exception as e:
        print(f"ğŸ›‘ [Face] äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return None


def _play_video(video_path: Path):
    """
    ç”Ÿæˆã•ã‚ŒãŸå‹•ç”»ã‚’å†ç”Ÿ
    ffplayã¾ãŸã¯macOSã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ“ãƒ¥ãƒ¼ã‚¢ãƒ¼ã§é–‹ã
    
    Args:
        video_path: å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    """
    try:
        print(f"ğŸ¬ [Face] å‹•ç”»å†ç”Ÿä¸­: {video_path.name}")
        
        # ffplayãŒã‚ã‚Œã°ä½¿ç”¨ï¼ˆãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°å†ç”Ÿï¼‰
        result = subprocess.run(["which", "ffplay"], 
                               stdout=subprocess.PIPE, 
                               stderr=subprocess.PIPE)
        
        if result.returncode == 0:
            # ffplayã§å†ç”Ÿï¼ˆå†ç”Ÿå®Œäº†ã¾ã§å¾…æ©Ÿï¼‰
            subprocess.run(["ffplay", "-autoexit", "-hide_banner", 
                          "-loglevel", "error", str(video_path)])
        else:
            # macOSã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ¬ãƒ¼ãƒ¤ãƒ¼ã§å†ç”Ÿï¼ˆéãƒ–ãƒ­ãƒƒã‚­ãƒ³ã‚°ï¼‰
            print(f"ğŸ’¡ [Face] ffplayãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ—ãƒ¬ãƒ¼ãƒ¤ãƒ¼ã§é–‹ãã¾ã™")
            subprocess.Popen(["open", str(video_path)], 
                            stdout=subprocess.DEVNULL, 
                            stderr=subprocess.DEVNULL)
            # ffprobeã§å‹•ç”»ã®é•·ã•ã‚’å–å¾—
            try:
                result = subprocess.run([
                    "ffprobe", "-v", "error", "-show_entries", 
                    "format=duration", "-of", "default=noprint_wrappers=1:nokey=1",
                    str(video_path)
                ], capture_output=True, text=True)
                duration = float(result.stdout.strip()) if result.returncode == 0 else 3.0
            except:
                duration = 3.0  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
            
            print(f"â³ [Face] å‹•ç”»å†ç”Ÿå¾…æ©Ÿ: {duration:.1f}ç§’")
            time.sleep(duration + 1)  # ä½™è£•ã‚’æŒãŸã›ã‚‹
            
    except Exception as e:
        print(f"âš ï¸ [Face] å‹•ç”»å†ç”Ÿã‚¨ãƒ©ãƒ¼: {e}")


async def _infer_and_play_tts(full_text: str):
    """
    Linuxä¸Šã®CosyVoice TTSã‚µãƒ¼ãƒãƒ¼ã«WebSocketçµŒç”±ã§ãƒ†ã‚­ã‚¹ãƒˆã‚’é€ä¿¡ã—ã€
    éŸ³å£°ã‚’å—ä¿¡ãƒ»å†ç”Ÿã™ã‚‹
    """
    if not full_text:
        return

    print(f"\nğŸ‘„ [Mouth] éŸ³å£°åˆæˆä¸­: '{full_text}'", flush=True)

    try:
        # TTSã¯åˆæˆã«æ™‚é–“ãŒã‹ã‹ã‚‹ã“ã¨ãŒã‚ã‚‹ãŸã‚ã€ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå´pingã§æ¥ç¶šãŒåˆ‡ã‚Œãªã„ã‚ˆã†ã«ã™ã‚‹
        async with websockets.connect(
            MOUTH_TTS_SERVER_URL,
            ping_interval=None,
            max_size=None,
        ) as ws:
            # æ¥ç¶šç¢ºèªãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å—ä¿¡ï¼ˆæœ€åˆã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼‰
            connect_msg = await ws.recv()
            connect_response = json.loads(connect_msg)
            if connect_response.get("status") == "connected":
                print(f"âœ… [Mouth] TTSæ¥ç¶šç¢ºèª: {connect_response.get('message')}")
            
            # ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡ï¼ˆLoRAè©±è€…IDã¯ç’°å¢ƒå¤‰æ•°ã§åˆ‡ã‚Šæ›¿ãˆï¼‰
            request = {
                "text": full_text,
                "mode": "sft",  # LoRAä½¿ç”¨æ™‚ã¯sftãƒ¢ãƒ¼ãƒ‰
                "speaker": SPEAKER_ID,
                "stream": False  # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç„¡åŠ¹åŒ–ï¼ˆç„¡é™ãƒ«ãƒ¼ãƒ—å›é¿ï¼‰
            }
            await ws.send(json.dumps(request))
            
            # æœ€åˆã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹ã‚’å—ä¿¡
            first_msg = await ws.recv()
            first_response = json.loads(first_msg)
            
            audio_chunks: list[bytes] = []
            played_realtime = False
            
            # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰
            if first_response.get("status") == "start" and first_response.get("stream"):
                print(f"ğŸµ [Mouth] ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°é–‹å§‹ (format: {first_response.get('format')}, rate: {first_response.get('sample_rate')}Hz)")
                
                # ãƒã‚¤ãƒŠãƒªãƒãƒ£ãƒ³ã‚¯ã‚’é€£ç¶šå—ä¿¡
                while True:
                    msg = await ws.recv()
                    
                    # JSONãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ï¼ˆdone/errorï¼‰ã‚’ãƒã‚§ãƒƒã‚¯
                    if isinstance(msg, str):
                        response = json.loads(msg)
                        if response.get("status") == "done":
                            print(f"âœ… [Mouth] ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å®Œäº† ({len(audio_chunks)} chunks)")
                            break
                        elif response.get("status") == "error":
                            print(f"ğŸ›‘ [Mouth] TTSã‚¨ãƒ©ãƒ¼: {response.get('message', 'ä¸æ˜ãªã‚¨ãƒ©ãƒ¼')}")
                            return
                    
                    # ãƒã‚¤ãƒŠãƒªãƒãƒ£ãƒ³ã‚¯ï¼ˆéŸ³å£°ãƒ‡ãƒ¼ã‚¿ï¼‰
                    elif isinstance(msg, bytes):
                        audio_chunks.append(msg)
                        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å†ç”Ÿ
                        try:
                            audio_stream.write(msg)
                            played_realtime = True
                        except Exception as e:
                            print(f"âš ï¸ [Mouth] ãƒãƒ£ãƒ³ã‚¯å†ç”Ÿã‚¨ãƒ©ãƒ¼: {e}")
            
            # éã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰
            elif first_response.get("status") == "complete":
                print(f"ğŸµ [Mouth] ä¸€æ‹¬éŸ³å£°å—ä¿¡ (format: {first_response.get('format')}, rate: {first_response.get('sample_rate')}Hz, size: {first_response.get('size')} bytes)")
                
                # éŸ³å£°ãƒ‡ãƒ¼ã‚¿å—ä¿¡
                audio_data = await ws.recv()
                if isinstance(audio_data, bytes):
                    audio_chunks.append(audio_data)
                
                # done ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å—ä¿¡
                done_msg = await ws.recv()
                done_response = json.loads(done_msg)
                if done_response.get("status") == "done":
                    print(f"âœ… [Mouth] ä¸€æ‹¬éŸ³å£°å®Œäº†")
            
            else:
                print(f"ğŸ›‘ [Mouth] äºˆæœŸã—ãªã„ãƒ¬ã‚¹ãƒãƒ³ã‚¹: {first_response}")
                return
            
            # å…¨ãƒãƒ£ãƒ³ã‚¯çµåˆ
            audio_bytes = b''.join(audio_chunks)
            print(f"ğŸ”Š [Mouth] ç·éŸ³å£°ãƒ‡ãƒ¼ã‚¿: {len(audio_bytes)} bytes ({len(audio_bytes)/48000:.2f}s)")

            # éŸ³å£°ã‚’ä¿å­˜ï¼ˆä»»æ„ï¼‰
            if SAVE_MOUTH_OUTPUT:
                saved = save_audio_result(audio_bytes)
                if saved:
                    print(f"ğŸ’¾ [Mouth] éŸ³å£°ä¿å­˜: {saved.name}")

            # faceç„¡ã—: éŸ³å£°ã‚’ãƒ­ãƒ¼ã‚«ãƒ«ã§å†ç”Ÿã—ã¦çµ‚äº†
            if not ENABLE_FACE_ANIMATION:
                if played_realtime:
                    return

                # WAVãƒ˜ãƒƒãƒ€ä»˜ãã‹ã‚‚ã—ã‚Œãªã„ã®ã§ä¸¡å¯¾å¿œ
                try:
                    if audio_bytes[:4] == b"RIFF" and b"WAVE" in audio_bytes[:16]:
                        with wave.open(io.BytesIO(audio_bytes), "rb") as wf:
                            frames = wf.readframes(wf.getnframes())
                        audio_stream.write(frames)
                    else:
                        audio_stream.write(audio_bytes)
                except Exception as exc:
                    print(f"âš ï¸ [Mouth] éŸ³å£°å†ç”Ÿã«å¤±æ•—ã—ã¾ã—ãŸ: {exc}")
                return

            # éŸ³å£°ã‚’ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
            temp_audio_path = OUTPUT_DIR / f"temp_audio_{datetime.now().strftime('%Y%m%d_%H%M%S_%f')}.wav"
            try:
                with wave.open(str(temp_audio_path), "wb") as wf:
                    wf.setnchannels(CHANNELS)
                    wf.setsampwidth(p.get_sample_size(AUDIO_FORMAT))
                    wf.setframerate(RATE)
                    wf.writeframes(audio_bytes)
                print(f"ğŸ’¾ [Mouth] ä¸€æ™‚éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜: {temp_audio_path.name}")
            except Exception as exc:
                print(f"âš ï¸ [Mouth] ä¸€æ™‚éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜å¤±æ•—: {exc}")
                return
            
            # é¡”ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆï¼ˆãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯ï¼‰
            print(f"ğŸ­ [Face] ãƒªãƒƒãƒ—ã‚·ãƒ³ã‚¯å‹•ç”»ç”Ÿæˆä¸­...")
            video_path = await _generate_face_animation(temp_audio_path)
            
            if video_path and video_path.exists():
                # å‹•ç”»ã‚’å†ç”Ÿï¼ˆéŸ³å£°ã‚‚å«ã¾ã‚Œã‚‹ï¼‰
                print(f"â–¶ï¸  [Face] å‹•ç”»å†ç”Ÿé–‹å§‹: {video_path.name}")
                _play_video(video_path)
                print(f"âœ… [Face] å‹•ç”»å†ç”Ÿå®Œäº†")
                
                # ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                try:
                    temp_audio_path.unlink()
                    video_path.unlink()
                    print(f"ğŸ§¹ [Face] ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤å®Œäº†")
                except Exception as e:
                    print(f"âš ï¸ [Face] ä¸€æ™‚ãƒ•ã‚¡ã‚¤ãƒ«å‰Šé™¤å¤±æ•—: {e}")
            else:
                print(f"ğŸ›‘ [Face] å‹•ç”»ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸ")
                # ä¸€æ™‚éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                try:
                    temp_audio_path.unlink()
                except Exception as e:
                    pass
                        
    except (ConnectionRefusedError, OSError) as e:
        print(f"ğŸ›‘ [Mouth] TTSã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“: {e}")
        print(f"ğŸ’¡ ç¢ºèª: Linuxä¸Šã§TTSã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ ({MOUTH_TTS_SERVER_URL})")
    except asyncio.TimeoutError:
        print(f"ğŸ›‘ [Mouth] æ¥ç¶šã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
    except Exception as e:
        print(f"ğŸ›‘ [Mouth] äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {type(e).__name__}: {e}")
        import traceback
        traceback.print_exc()


async def stream_to_tts(text_stream_generator):
    """
    LLMã‹ã‚‰é€ã‚‰ã‚Œã¦ãã‚‹ãƒ†ã‚­ã‚¹ãƒˆã‚’ä¸€æ‹¬ã§TTSã«é€ä¿¡ã™ã‚‹
    ãƒãƒ£ãƒ³ã‚¯ã«åˆ†ã‘ãšã«å®Œå…¨ãªæ–‡ç« ã‚’ä¸€åº¦ã«å‡¦ç†
    """
    full_text = ""

    # ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¨ã¦åé›†
    async for text_chunk in text_stream_generator:
        if not text_chunk:
            continue
        full_text += text_chunk

    # æ”¹è¡Œã‚’è¿½åŠ 
    print()

    # ä¸€æ‹¬ã§é€ä¿¡
    if full_text.strip():
        await _infer_and_play_tts(full_text.strip())

async def handle_llm_response(text: str):
    """
    é ­ï¼ˆLLMï¼‰ã‚µãƒ¼ãƒãƒ¼ã«ãƒ†ã‚­ã‚¹ãƒˆã‚’é€ä¿¡ã—ã€
    ä¸€æ‹¬ã§å›ç­”ã‚’å—ã‘å–ã‚Šã€TTSã«æµã™
    """
    try:
        async with httpx.AsyncClient(timeout=None) as client:
            print(f"ğŸ§  [Head] æ€è€ƒä¸­...: '{text}'")
            
            # ä¸€æ‹¬ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
            response = await client.post(HEAD_LLM_SERVER_URL, json={"text": text})
            
            if response.status_code != 200:
                print(f"ğŸ›‘ [Head] LLMã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼ (Status: {response.status_code})")
                error_body = response.text
                if error_body:
                    print(f"     è©³ç´°: {error_body[:200]}")
                return

            # JSONå¿œç­”ã‚’å–å¾—
            result = response.json()
            full_response = result.get("response", "")
            
            print(f"ğŸ§  [Head] å›ç­”ç”Ÿæˆå®Œäº†: {len(full_response)}æ–‡å­—")
            print(f"ğŸ’¬ [Head] å›ç­”: {full_response}")
            
            # å®Œå…¨ãªå¿œç­”ã‚’TTSã«é€ä¿¡ï¼ˆã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ã«å¤‰æ›ï¼‰
            async def text_generator():
                yield full_response
            
            await stream_to_tts(text_generator())

    except httpx.ConnectError:
        print(f"ğŸ›‘ [Head] LLMã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“")
        print(f"ğŸ’¡ ç¢ºèª: LLMã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ ({HEAD_LLM_SERVER_URL})")
    except httpx.TimeoutException:
        print(f"ğŸ›‘ [Head] LLMã‚µãƒ¼ãƒãƒ¼ã®ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ")
    except Exception as e:
        print(f"ğŸ›‘ [Head] äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")

async def run_controller():
    """
    ãƒ¡ã‚¤ãƒ³ã®ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼
    è€³ï¼ˆSTTï¼‰ã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã—ã€ãƒ†ã‚­ã‚¹ãƒˆã‚’å¾…æ©Ÿã™ã‚‹
    """
    global processing_lock
    if processing_lock is None:
        processing_lock = asyncio.Lock()

    print("=" * 60)
    print("ğŸš€ President Clone ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼ã‚’èµ·å‹•ã—ã¾ã™")
    print("=" * 60)
    print(f"\nğŸ”Œ æ¥ç¶šå…ˆ:")
    print(f"  ğŸ‘‚ è€³ (STT): {EARS_STT_SERVER_URL}")
    print(f"  ğŸ§  é ­ (LLM): {HEAD_LLM_SERVER_URL}")
    print(f"  ğŸ‘„ å£ (TTS): {MOUTH_TTS_SERVER_URL}")
    print(f"  ğŸ­ é¡” (Face): {FACE_SERVER_URL} {'âœ… æœ‰åŠ¹' if ENABLE_FACE_ANIMATION else 'âŒ ç„¡åŠ¹'}")
    if ENABLE_FACE_ANIMATION:
        print(f"     é¡”ç”»åƒ: {FACE_IMAGE_PATH} {'âœ…' if FACE_IMAGE_PATH.exists() else 'âŒ æœªè¨­å®š'}")
    print(f"\nğŸ’¡ ãƒ’ãƒ³ãƒˆ:")
    print(f"  - Google Cloud Speech-to-Text APIã‚’ä½¿ç”¨")
    print(f"  - CosyVoice2-0.5Bã§éŸ³å£°åˆæˆ")
    if ENABLE_FACE_ANIMATION:
        print(f"  - Wav2Lipã§é¡”ã‚¢ãƒ‹ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ç”Ÿæˆ")
    print(f"  - è©±ã—ã‹ã‘ã‚‹ã¨è‡ªå‹•çš„ã«èªè­˜ãƒ»å¿œç­”ã—ã¾ã™")
    print("=" * 60)
    
    print(f"\nğŸ‘‚ [Ears] STTã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šä¸­...")
    
    retry_count = 0
    max_retries = 3
    
    while retry_count < max_retries:
        try:
            async with websockets.connect(EARS_STT_SERVER_URL) as websocket:
                print("âœ… [Ears] æ¥ç¶šæˆåŠŸï¼éŸ³å£°ã‚’å¾…æ©Ÿä¸­...\n")
                
                # ãƒªã‚¹ãƒ‹ãƒ³ã‚°å†é–‹ã‚’æŒ‡ç¤º
                try:
                    await websocket.send("RESUME_LISTENING")
                except Exception as e:
                    print(f"âš ï¸  [Ears] ãƒªã‚¹ãƒ‹ãƒ³ã‚°å†é–‹ã‚³ãƒãƒ³ãƒ‰é€ä¿¡å¤±æ•—: {e}")
                
                async for stt_text in websocket:
                    message = stt_text.strip()
                    
                    # ç©ºã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã‚¹ã‚­ãƒƒãƒ—
                    if not message:
                        continue
                    
                    # ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®å‡¦ç†
                    if message.upper().startswith("ACK:"):
                        print(f"ğŸ“¨ [Ears] {message}")
                        continue
                    
                    if message.upper().startswith("STATE:"):
                        state = message.split(":", 1)[1].strip()
                        if state == "LISTENING":
                            print(f"ğŸ¤ [Ears] ãƒªã‚¹ãƒ‹ãƒ³ã‚°ä¸­...")
                        elif state == "PAUSED":
                            print(f"â¸ï¸  [Ears] ãƒªã‚¹ãƒ‹ãƒ³ã‚°ä¸€æ™‚åœæ­¢")
                        continue
                    
                    # éŸ³å£°èªè­˜çµæœã‚’å—ä¿¡
                    print(f"\n{'=' * 60}")
                    print(f"ğŸ‘‚ [Ears] éŸ³å£°èªè­˜çµæœ: '{message}'")
                    print(f"{'=' * 60}")

                    # ãƒªã‚¹ãƒ‹ãƒ³ã‚°ã‚’ä¸€æ™‚åœæ­¢ï¼ˆå¿œç­”ä¸­ã¯éŸ³å£°èªè­˜ã—ãªã„ï¼‰
                    try:
                        await websocket.send("PAUSE_LISTENING")
                    except Exception as e:
                        print(f"âš ï¸  [Ears] ãƒªã‚¹ãƒ‹ãƒ³ã‚°åœæ­¢ã‚³ãƒãƒ³ãƒ‰é€ä¿¡å¤±æ•—: {e}")
                    
                    # LLMã«é€ä¿¡ã—ã¦å¿œç­”ã‚’å–å¾—ãƒ»å†ç”Ÿ
                    async with processing_lock:
                        try:
                            await handle_llm_response(message)
                        except Exception as e:
                            print(f"ğŸ›‘ [å‡¦ç†ã‚¨ãƒ©ãƒ¼] {e}")
                        finally:
                            # ãƒªã‚¹ãƒ‹ãƒ³ã‚°ã‚’å†é–‹
                            try:
                                await websocket.send("RESUME_LISTENING")
                                print(f"\n{'=' * 60}")
                                print(f"ğŸ¤ [Ears] æ¬¡ã®éŸ³å£°ã‚’å¾…æ©Ÿä¸­...")
                                print(f"{'=' * 60}\n")
                            except Exception as e:
                                print(f"âš ï¸  [Ears] ãƒªã‚¹ãƒ‹ãƒ³ã‚°å†é–‹ã‚³ãƒãƒ³ãƒ‰é€ä¿¡å¤±æ•—: {e}")
                
                # æ¥ç¶šãŒæ­£å¸¸ã«çµ‚äº†ã—ãŸå ´åˆã¯ãƒªãƒˆãƒ©ã‚¤ã—ãªã„
                break

        except websockets.exceptions.ConnectionClosedError as e:
            retry_count += 1
            print(f"ğŸ›‘ [Ears] ã‚µãƒ¼ãƒãƒ¼ã¨ã®æ¥ç¶šãŒåˆ‡ã‚Œã¾ã—ãŸ: {e}")
            if retry_count < max_retries:
                print(f"ğŸ”„ {retry_count}/{max_retries}å›ç›®ã®å†æ¥ç¶šã‚’è©¦ã¿ã¾ã™ï¼ˆ3ç§’å¾Œï¼‰...")
                await asyncio.sleep(3)
            else:
                print(f"âŒ [Ears] æœ€å¤§å†æ¥ç¶šå›æ•°ã«é”ã—ã¾ã—ãŸã€‚")
                
        except ConnectionRefusedError:
            print(f"\nğŸ›‘ [Ears] STTã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã§ãã¾ã›ã‚“ã€‚")
            print(f"ğŸ’¡ ä»¥ä¸‹ã‚’ç¢ºèªã—ã¦ãã ã•ã„:")
            print(f"  1. STTã‚µãƒ¼ãƒãƒ¼ãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹")
            print(f"     â†’ cd ears_stt && python3 run_stt_server.py")
            print(f"  2. ãƒãƒ¼ãƒˆ8001ãŒä½¿ç”¨å¯èƒ½ã‹")
            print(f"  3. Google Cloudèªè¨¼ãŒå®Œäº†ã—ã¦ã„ã‚‹ã‹")
            print(f"     â†’ gcloud auth application-default login")
            break
            
        except Exception as e:
            retry_count += 1
            print(f"ğŸ›‘ [Ears] äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
            if retry_count < max_retries:
                print(f"ğŸ”„ {retry_count}/{max_retries}å›ç›®ã®å†æ¥ç¶šã‚’è©¦ã¿ã¾ã™ï¼ˆ3ç§’å¾Œï¼‰...")
                await asyncio.sleep(3)
            else:
                print(f"âŒ [Ears] æœ€å¤§å†æ¥ç¶šå›æ•°ã«é”ã—ã¾ã—ãŸã€‚")
                break
    
    # çµ‚äº†å‡¦ç†
    print("\nğŸ§¹ ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ä¸­...")
    try:
        if audio_stream.is_active():
            audio_stream.stop_stream()
        audio_stream.close()
        p.terminate()
        print("âœ… ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’çµ‚äº†ã—ã¾ã—ãŸ")
    except Exception as e:
        print(f"âš ï¸  ã‚ªãƒ¼ãƒ‡ã‚£ã‚ªã‚¹ãƒˆãƒªãƒ¼ãƒ çµ‚äº†ã‚¨ãƒ©ãƒ¼: {e}")

# --- ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®å®Ÿè¡Œ ---
if __name__ == "__main__":
    try:
        asyncio.run(run_controller())
    except KeyboardInterrupt:
        print("\nğŸ›‘ ã‚³ãƒ³ãƒˆãƒ­ãƒ¼ãƒ©ãƒ¼ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
