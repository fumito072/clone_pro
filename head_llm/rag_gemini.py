"""
Google Gemini Embeddings APIã‚’ä½¿ã£ãŸé«˜ç²¾åº¦RAG
æ–‡è„ˆãƒ»æ„å‘³ãƒ»åŒç¾©èªã‚’ç†è§£ã—ãŸãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢
OpenAI Embeddings APIã¨äº’æ›æ€§ã®ã‚ã‚‹ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹
"""
import json
import numpy as np
from pathlib import Path
from typing import List, Dict
import google.generativeai as genai


class GeminiRAG:
    """Google Gemini Embeddings APIã‚’ä½¿ã£ãŸãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢RAG"""
    
    def __init__(self, knowledge_dir: Path):
        self.knowledge_dir = Path(knowledge_dir)
        # Gemini APIã¯æ—¢ã«genai.configure()ã§è¨­å®šæ¸ˆã¿ã‚’æƒ³å®š
        self.chunks: List[Dict] = []
        self.embeddings: List[List[float]] = []
        
        self._load_knowledge()
        self._build_embeddings()
    
    def _load_knowledge(self):
        """JSONLãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒŠãƒ¬ãƒƒã‚¸ã‚’èª­ã¿è¾¼ã¿"""
        if not self.knowledge_dir.exists():
            print(f"âš ï¸  ãƒŠãƒ¬ãƒƒã‚¸ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.knowledge_dir}")
            return
        
        json_files = list(self.knowledge_dir.glob("*.json")) + list(self.knowledge_dir.glob("*.jsonl"))
        if not json_files:
            print(f"âš ï¸  JSONãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.knowledge_dir}")
            return
        
        for json_file in json_files:
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    # JSONLå½¢å¼ã‚’æƒ³å®šï¼ˆ1è¡Œ1JSONï¼‰
                    for line in f:
                        line = line.strip()
                        if line:
                            chunk = json.loads(line)
                            self.chunks.append(chunk)
            except Exception as e:
                print(f"âš ï¸  {json_file.name}ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        
        print(f"âœ… ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹èª­ã¿è¾¼ã¿å®Œäº†: {len(self.chunks)}ä»¶")
    
    def _build_embeddings(self):
        """å…¨ãƒãƒ£ãƒ³ã‚¯ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼ˆåˆå›ã®ã¿ï¼‰"""
        if not self.chunks:
            return
        
        print(f"ğŸ”„ Gemini Embeddings ã§ãƒ™ã‚¯ãƒˆãƒ«åŒ–ä¸­... ({len(self.chunks)}ä»¶)")
        
        try:
            # å…¨ãƒãƒ£ãƒ³ã‚¯ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–
            texts = [chunk['text'] for chunk in self.chunks]
            
            # Gemini Embeddings APIã‚’ä½¿ç”¨
            # models/text-embedding-004 ã¯æœ€æ–°ã®åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«
            # 768æ¬¡å…ƒã€æ—¥æœ¬èªå¯¾å¿œã€ç„¡æ–™æ ãŒå¤§ãã„
            for text in texts:
                result = genai.embed_content(
                    model="models/text-embedding-004",
                    content=text,
                    task_type="retrieval_document"  # æ–‡æ›¸æ¤œç´¢ç”¨
                )
                self.embeddings.append(result['embedding'])
            
            print(f"âœ… ãƒ™ã‚¯ãƒˆãƒ«åŒ–å®Œäº†: {len(self.embeddings)}ä»¶")
            print(f"ğŸ“Š ãƒ™ã‚¯ãƒˆãƒ«æ¬¡å…ƒ: {len(self.embeddings[0])}æ¬¡å…ƒ")
            
        except Exception as e:
            print(f"âŒ ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            self.embeddings = []
    
    def search(self, query: str, top_k: int = 3) -> List[Dict]:
        """
        æ„å‘³ãƒ™ãƒ¼ã‚¹ã§ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢
        
        æ–‡è„ˆãƒ»æ„å‘³ãƒ»åŒç¾©èªã‚’ç†è§£ã—ãŸæ¤œç´¢:
        - "ã©ã†ã—ã¦åŒ»å­¦éƒ¨ã‚’è¾ã‚ãŸã®ï¼Ÿ" ã¨ "åŒ»å­¦éƒ¨é€€å­¦ã®ç†ç”±" ãŒåŒã˜æ„å‘³ã¨èªè­˜
        - "çŒ«é£¼ã£ã¦ã‚‹ï¼Ÿ" ã¨ "çŒ«ã‚’2åŒ¹é£¼è‚²" ãŒä¸€è‡´
        - "å°†æ¥ä½•ãŒã—ãŸã„ï¼Ÿ" ã¨ "æœ€çµ‚ãƒ“ã‚¸ãƒ§ãƒ³" ãŒé–¢é€£
        
        Args:
            query: æ¤œç´¢ã‚¯ã‚¨ãƒª
            top_k: è¿”ã™æœ€å¤§ä»¶æ•°
        
        Returns:
            é–¢é€£ã™ã‚‹ãƒãƒ£ãƒ³ã‚¯ã®ãƒªã‚¹ãƒˆï¼ˆã‚¹ã‚³ã‚¢ãŒé«˜ã„é †ï¼‰
        """
        if not self.chunks or not self.embeddings:
            return []
        
        try:
            # ã‚¯ã‚¨ãƒªã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–
            query_result = genai.embed_content(
                model="models/text-embedding-004",
                content=query,
                task_type="retrieval_query"  # ã‚¯ã‚¨ãƒªç”¨
            )
            query_embedding = query_result['embedding']
            
            # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—
            similarities = []
            for doc_embedding in self.embeddings:
                similarity = self._cosine_similarity(query_embedding, doc_embedding)
                similarities.append(similarity)
            
            # ã‚¹ã‚³ã‚¢ãŒé«˜ã„é †ã«ã‚½ãƒ¼ãƒˆ
            ranked_indices = np.argsort(similarities)[::-1][:top_k]
            
            results = []
            for idx in ranked_indices:
                chunk = self.chunks[idx].copy()
                chunk['score'] = float(similarities[idx])
                results.append(chunk)
            
            return results
            
        except Exception as e:
            print(f"âŒ æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def _cosine_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—"""
        vec1 = np.array(vec1)
        vec2 = np.array(vec2)
        
        dot_product = np.dot(vec1, vec2)
        norm1 = np.linalg.norm(vec1)
        norm2 = np.linalg.norm(vec2)
        
        if norm1 == 0 or norm2 == 0:
            return 0.0
        
        return dot_product / (norm1 * norm2)
    
    def format_context(self, search_results: List[Dict], max_length: int = 1000) -> str:
        """
        æ¤œç´¢çµæœã‚’LLMãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”¨ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã«æ•´å½¢
        
        Args:
            search_results: searchãƒ¡ã‚½ãƒƒãƒ‰ã®çµæœ
            max_length: æœ€å¤§æ–‡å­—æ•°
        
        Returns:
            æ•´å½¢ã•ã‚ŒãŸã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ–‡å­—åˆ—
        """
        if not search_results:
            return ""
        
        context_parts = []
        total_length = 0
        
        for i, result in enumerate(search_results, 1):
            text = result['text']
            score = result.get('score', 0)
            
            # ã‚¹ã‚³ã‚¢ãŒä½ã™ãã‚‹ï¼ˆé–¢é€£æ€§ãŒè–„ã„ï¼‰å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            if score < 0.3:
                continue
            
            part = f"[å‚è€ƒ{i}] {text}"
            part_length = len(part)
            
            if total_length + part_length > max_length:
                break
            
            context_parts.append(part)
            total_length += part_length
        
        return "\n\n".join(context_parts)


# ä½¿ç”¨ä¾‹
if __name__ == "__main__":
    import os
    
    # Gemini APIè¨­å®š
    api_key = os.getenv("GEMINI_API_KEY")
    if api_key:
        genai.configure(api_key=api_key)
    
    # RAGåˆæœŸåŒ–
    knowledge_dir = Path(__file__).parent / "knowledge" / "narisawa"
    rag = GeminiRAG(knowledge_dir)
    
    # æ¤œç´¢ãƒ†ã‚¹ãƒˆ
    test_queries = [
        "åŒ»å­¦éƒ¨ã‚’è¾ã‚ãŸç†ç”±ã¯ï¼Ÿ",
        "çŒ«ã‚’é£¼ã£ã¦ã„ã¾ã™ã‹ï¼Ÿ",
        "å°†æ¥ã®å¤¢ã¯ï¼Ÿ"
    ]
    
    for query in test_queries:
        print(f"\nğŸ” ã‚¯ã‚¨ãƒª: {query}")
        results = rag.search(query, top_k=2)
        for i, result in enumerate(results, 1):
            print(f"  [{i}] ã‚¹ã‚³ã‚¢: {result['score']:.3f}")
            print(f"      {result['text'][:100]}...")
