"""LLM server entrypoint.

ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ OpenAI ã‚’ä½¿ç”¨ã€‚
Gemini ã‚’ä½¿ã†å ´åˆã¯ run_llm_server_gemini.py ã‚’ç›´æ¥èµ·å‹•ã—ã¦ãã ã•ã„ã€‚
"""

import uvicorn

from run_llm_server_openai import MODEL_NAME, app


if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ§  Narisawa LLM Server (OpenAI) ã‚’èµ·å‹•ã—ã¾ã™")
    print("=" * 60)
    print(f"ãƒ¢ãƒ‡ãƒ«: {MODEL_NAME}")
    print("ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ: http://127.0.0.1:8002/think")
    print("=" * 60)
    uvicorn.run(app, host="0.0.0.0", port=8002)
