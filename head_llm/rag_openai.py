"""
OpenAI Embeddings APIã‚’ä½¿ã£ãŸé«˜ç²¾åº¦RAG
æ–‡è„ˆãƒ»æ„å‘³ãƒ»åŒç¾©èªã‚’ç†è§£ã—ãŸãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢
"""
import json
import numpy as np
from pathlib import Path
from typing import List, Dict
from openai import OpenAI


class OpenAIRAG:
    """OpenAI Embeddings APIã‚’ä½¿ã£ãŸãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢RAG"""
    
    def __init__(self, knowledge_dir: Path):
        self.knowledge_dir = Path(knowledge_dir)
        self.client = OpenAI()  # ç’°å¢ƒå¤‰æ•° OPENAI_API_KEY ã‚’è‡ªå‹•èª­ã¿è¾¼ã¿
        self.chunks: List[Dict] = []
        self.embeddings: List[List[float]] = []
        
        self._load_knowledge()
        self._build_embeddings()
    
    def _load_knowledge(self):
        """JSONLãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒŠãƒ¬ãƒƒã‚¸ã‚’èª­ã¿è¾¼ã¿"""
        if not self.knowledge_dir.exists():
            print(f"âš ï¸  ãƒŠãƒ¬ãƒƒã‚¸ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.knowledge_dir}")
            return
        
        json_files = list(self.knowledge_dir.glob("*.json")) + list(self.knowledge_dir.glob("*.jsonl"))
        if not json_files:
            print(f"âš ï¸  JSONãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.knowledge_dir}")
            return
        
        for json_file in json_files:
            try:
                with open(json_file, 'r', encoding='utf-8') as f:
                    # JSONLå½¢å¼ã‚’æƒ³å®šï¼ˆ1è¡Œ1JSONï¼‰
                    for line in f:
                        line = line.strip()
                        if line:
                            chunk = json.loads(line)
                            self.chunks.append(chunk)
            except Exception as e:
                print(f"âš ï¸  {json_file.name}ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        
        print(f"âœ… ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹èª­ã¿è¾¼ã¿å®Œäº†: {len(self.chunks)}ä»¶")
    
    def _build_embeddings(self):
        """å…¨ãƒãƒ£ãƒ³ã‚¯ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼ˆåˆå›ã®ã¿ï¼‰"""
        if not self.chunks:
            return
        
        print(f"ğŸ”„ Embeddings API ã§ãƒ™ã‚¯ãƒˆãƒ«åŒ–ä¸­... ({len(self.chunks)}ä»¶)")
        
        try:
            # å…¨ãƒãƒ£ãƒ³ã‚¯ã‚’ä¸€æ‹¬ã§ãƒ™ã‚¯ãƒˆãƒ«åŒ–ï¼ˆåŠ¹ç‡çš„ï¼‰
            texts = [chunk['text'] for chunk in self.chunks]
            
            response = self.client.embeddings.create(
                model="text-embedding-3-small",  # å®‰ä¾¡ã§é«˜ç²¾åº¦
                input=texts
            )
            
            self.embeddings = [item.embedding for item in response.data]
            
            print(f"âœ… ãƒ™ã‚¯ãƒˆãƒ«åŒ–å®Œäº†: {len(self.embeddings)}ä»¶")
            print(f"ğŸ“Š ãƒ™ã‚¯ãƒˆãƒ«æ¬¡å…ƒ: {len(self.embeddings[0])}æ¬¡å…ƒ")
            
        except Exception as e:
            print(f"âŒ ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã‚¨ãƒ©ãƒ¼: {e}")
            self.embeddings = []
    
    def search(self, query: str, top_k: int = 3) -> List[Dict]:
        """
        æ„å‘³ãƒ™ãƒ¼ã‚¹ã§ãƒ™ã‚¯ãƒˆãƒ«æ¤œç´¢
        
        æ–‡è„ˆãƒ»æ„å‘³ãƒ»åŒç¾©èªã‚’ç†è§£ã—ãŸæ¤œç´¢:
        - "ã©ã†ã—ã¦åŒ»å­¦éƒ¨ã‚’è¾ã‚ãŸã®ï¼Ÿ" ã¨ "åŒ»å­¦éƒ¨é€€å­¦ã®ç†ç”±" ãŒåŒã˜æ„å‘³ã¨èªè­˜
        - "çŒ«é£¼ã£ã¦ã‚‹ï¼Ÿ" ã¨ "çŒ«ã‚’2åŒ¹é£¼è‚²" ãŒä¸€è‡´
        - "å°†æ¥ä½•ãŒã—ãŸã„ï¼Ÿ" ã¨ "æœ€çµ‚ãƒ“ã‚¸ãƒ§ãƒ³" ãŒé–¢é€£
        
        Args:
            query: æ¤œç´¢ã‚¯ã‚¨ãƒª
            top_k: è¿”ã™æœ€å¤§ä»¶æ•°
        
        Returns:
            é–¢é€£ã™ã‚‹ãƒãƒ£ãƒ³ã‚¯ã®ãƒªã‚¹ãƒˆï¼ˆã‚¹ã‚³ã‚¢ãŒé«˜ã„é †ï¼‰
        """
        if not self.chunks or not self.embeddings:
            return []
        
        try:
            # ã‚¯ã‚¨ãƒªã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–
            query_response = self.client.embeddings.create(
                model="text-embedding-3-small",
                input=query
            )
            query_embedding = query_response.data[0].embedding
            
            # ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—
            similarities = []
            for chunk_embedding in self.embeddings:
                similarity = self._cosine_similarity(query_embedding, chunk_embedding)
                similarities.append(similarity)
            
            # ã‚¹ã‚³ã‚¢ã®é«˜ã„é †ã«ã‚½ãƒ¼ãƒˆ
            top_indices = np.argsort(similarities)[-top_k:][::-1]
            
            # çµæœã‚’è¿”ã™
            results = []
            for idx in top_indices:
                chunk = self.chunks[idx].copy()
                chunk['score'] = float(similarities[idx])  # ã‚¹ã‚³ã‚¢ã‚’è¿½åŠ 
                results.append(chunk)
            
            return results
            
        except Exception as e:
            print(f"âŒ æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return []
    
    def _cosine_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """ã‚³ã‚µã‚¤ãƒ³é¡ä¼¼åº¦ã‚’è¨ˆç®—"""
        vec1 = np.array(vec1)
        vec2 = np.array(vec2)
        
        dot_product = np.dot(vec1, vec2)
        norm1 = np.linalg.norm(vec1)
        norm2 = np.linalg.norm(vec2)
        
        if norm1 == 0 or norm2 == 0:
            return 0.0
        
        return dot_product / (norm1 * norm2)
    
    def format_context(self, chunks: List[Dict]) -> str:
        """æ¤œç´¢çµæœã‚’æ–‡å­—åˆ—ã«æ•´å½¢"""
        if not chunks:
            return ""
        
        context_parts = []
        for i, chunk in enumerate(chunks, 1):
            text = chunk.get('text', '')
            chunk_id = chunk.get('id', '?')
            score = chunk.get('score', 0.0)
            
            context_parts.append(
                f"[å‚è€ƒæƒ…å ± {i}] (ID: {chunk_id}, é–¢é€£åº¦: {score:.2f})\n{text}"
            )
        
        return "\n\n".join(context_parts)
