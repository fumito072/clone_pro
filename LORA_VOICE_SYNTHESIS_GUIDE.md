# LoRAéŸ³å£°åˆæˆã‚’å‹•ä½œã•ã›ã‚‹ã¾ã§ã®å®Œå…¨æ‰‹é †

## ğŸ“‹ ç›®æ¬¡
1. [å•é¡Œã®æœ¬è³ª](#å•é¡Œã®æœ¬è³ª)
2. [è§£æ±ºã¾ã§ã®æµã‚Œ](#è§£æ±ºã¾ã§ã®æµã‚Œ)
3. [å®Ÿè£…ã®è©³ç´°](#å®Ÿè£…ã®è©³ç´°)
4. [ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆ](#ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆ)
5. [ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°](#ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°)

---

## å•é¡Œã®æœ¬è³ª

### CosyVoice2-0.5Bã®åˆ¶ç´„
```python
# CosyVoice2-0.5Bã‚’ãƒ­ãƒ¼ãƒ‰
model = CosyVoice2('/path/to/CosyVoice2-0.5B')

# å•é¡Œ: æ¨™æº–ã®speaker IDãŒå­˜åœ¨ã—ãªã„
print(model.frontend.spk2info)  # â†’ {} (ç©ºã®è¾æ›¸)

# inference_sftã¯å†…éƒ¨ã§spk2info[spk_id]ã‚’å‚ç…§
# ã©ã‚“ãªspk_idã‚’æ¸¡ã—ã¦ã‚‚KeyErrorãŒç™ºç”Ÿ
model.inference_sft("ãƒ†ã‚­ã‚¹ãƒˆ", "yotaro")  # âŒ KeyError: 'yotaro'
```

**ã¤ã¾ã‚Š**: LoRAã§ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã—ã¦ã‚‚ã€ãã®ã¾ã¾ã§ã¯å­¦ç¿’ã—ãŸè©±è€…IDãŒä½¿ãˆãªã„ã€‚

---

## è§£æ±ºã¾ã§ã®æµã‚Œ

### ã‚¹ãƒ†ãƒƒãƒ—1: LoRAãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã§ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª

```bash
lora_yotaro/
â”œâ”€â”€ spk2embedding.pt      # â­ è©±è€…åŸ‹ã‚è¾¼ã¿ï¼ˆé‡è¦ï¼ï¼‰
â”œâ”€â”€ spk2utt               # speaker_id: "yotaro"
â”œâ”€â”€ segments/             # å­¦ç¿’ç”¨éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«
â”œâ”€â”€ text                  # ãƒ†ã‚­ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
â””â”€â”€ ...

lora_yotaro_trained/
â””â”€â”€ epoch_12_whole.pt     # â­ LoRAå­¦ç¿’æ¸ˆã¿é‡ã¿
```

**é‡è¦ãªç™ºè¦‹**:
- `spk2embedding.pt`: å­¦ç¿’æ™‚ã«æŠ½å‡ºã•ã‚ŒãŸè©±è€…åŸ‹ã‚è¾¼ã¿ãƒ™ã‚¯ãƒˆãƒ«
- `epoch_12_whole.pt`: LoRAé©ç”¨å¾Œã®LLMé‡ã¿

### ã‚¹ãƒ†ãƒƒãƒ—2: è©±è€…åŸ‹ã‚è¾¼ã¿ã®æ§‹é€ ã‚’ç¢ºèª

```python
import torch

spk2embedding = torch.load('lora_yotaro/spk2embedding.pt')
print(spk2embedding.keys())  # â†’ dict_keys(['yotaro'])
print(type(spk2embedding['yotaro']))  # â†’ <class 'list'>
print(len(spk2embedding['yotaro']))   # â†’ 192
```

**å•é¡Œç‚¹**:
- ãƒ‡ãƒ¼ã‚¿å‹ãŒ `list`ï¼ˆTensorã§ã¯ãªã„ï¼‰
- 1æ¬¡å…ƒãƒ‡ãƒ¼ã‚¿ `[192]`ï¼ˆãƒãƒƒãƒæ¬¡å…ƒãŒãªã„ï¼‰

### ã‚¹ãƒ†ãƒƒãƒ—3: æ­£ã—ã„å½¢å¼ã«å¤‰æ›

```python
# ãƒªã‚¹ãƒˆ â†’ Tensor
embedding = torch.tensor(spk2embedding['yotaro'])
print(embedding.shape)  # â†’ torch.Size([192])

# 2æ¬¡å…ƒåŒ–ï¼ˆãƒãƒƒãƒæ¬¡å…ƒã‚’è¿½åŠ ï¼‰
embedding = embedding.unsqueeze(0)
print(embedding.shape)  # â†’ torch.Size([1, 192])
```

**ãªãœ2æ¬¡å…ƒåŒ–ãŒå¿…è¦ï¼Ÿ**

CosyVoiceã®å†…éƒ¨ã‚³ãƒ¼ãƒ‰ï¼ˆ`cosyvoice/flow/flow.py`ï¼‰:
```python
def inference(self, token, embedding, ...):
    # ...
    embedding = F.normalize(embedding, dim=1)  # dim=1 ã§æ­£è¦åŒ–
    # ...
```

- `F.normalize(..., dim=1)` ã¯ã€Œ2æ¬¡å…ƒç›®ã‚’æ­£è¦åŒ–ã€ã™ã‚‹ã“ã¨ã‚’æ„å‘³
- 1æ¬¡å…ƒ `[192]` ã ã¨ `IndexError: Dimension out of range (expected to be in range of [-1, 0], but got 1)`

### ã‚¹ãƒ†ãƒƒãƒ—4: ãƒ¢ãƒ‡ãƒ«ã«è©±è€…æƒ…å ±ã‚’ç™»éŒ²

```python
from cosyvoice.cli.cosyvoice import CosyVoice2
import torch

# 1. ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
model = CosyVoice2('/path/to/CosyVoice2-0.5B')

# 2. LoRAé‡ã¿ã‚’ãƒ­ãƒ¼ãƒ‰
checkpoint = torch.load('lora_yotaro_trained/epoch_12_whole.pt', map_location='cpu')
lora_state_dict = {
    k: v for k, v in checkpoint.items() 
    if k not in ['epoch', 'step', 'optimizer', 'scheduler']
}
model.model.llm.load_state_dict(lora_state_dict, strict=False)

# 3. è©±è€…åŸ‹ã‚è¾¼ã¿ã‚’ãƒ­ãƒ¼ãƒ‰ & å¤‰æ›
spk2embedding = torch.load('lora_yotaro/spk2embedding.pt')
yotaro_emb = torch.tensor(spk2embedding['yotaro']).unsqueeze(0)  # [1, 192]

# 4. â­ ãƒ¢ãƒ‡ãƒ«ã«è©±è€…IDã‚’ç™»éŒ²
model.frontend.spk2info['yotaro'] = {
    'embedding': yotaro_emb
}

# 5. âœ… ã“ã‚Œã§å‹•ä½œã™ã‚‹ï¼
result = model.inference_sft('ã“ã‚“ã«ã¡ã¯ã€ã‚ˆãƒ¼ãŸã‚ãƒ¼ã§ã™', 'yotaro', stream=False)
```

---

## å®Ÿè£…ã®è©³ç´°

### `CosyVoiceEngine` ã‚¯ãƒ©ã‚¹ï¼ˆWSLå´ï¼‰

**ãƒ•ã‚¡ã‚¤ãƒ«**: `/mnt/c/Users/fhoshina/development/CosyVoice/api_server/cosyvoice_engine.py`

```python
class CosyVoiceEngine:
    def __init__(self, model_dir, speaker_config_path):
        self.model = CosyVoice2(model_dir)
        self._lora_cache = {}        # LoRAé‡ã¿ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        self._embedding_cache = {}   # åŸ‹ã‚è¾¼ã¿ã®ã‚­ãƒ£ãƒƒã‚·ãƒ¥
        self._load_speaker_config()  # speaker_config.jsonèª­ã¿è¾¼ã¿
    
    def load_speaker_lora(self, speaker_id: str) -> bool:
        """LoRAãƒ¢ãƒ‡ãƒ«ã¨è©±è€…åŸ‹ã‚è¾¼ã¿ã‚’ãƒ­ãƒ¼ãƒ‰"""
        
        # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç¢ºèªï¼ˆ2å›ç›®ä»¥é™ã¯é«˜é€Ÿï¼‰
        if speaker_id in self._lora_cache:
            self.model.model.llm.load_state_dict(self._lora_cache[speaker_id], strict=False)
            return True
        
        speaker_info = self.speaker_config['speakers'][speaker_id]
        lora_path = speaker_info['lora_model_path']
        embedding_path = speaker_info['spk_embedding_path']
        
        # 1. LoRAé‡ã¿ãƒ­ãƒ¼ãƒ‰
        checkpoint = torch.load(lora_path, map_location='cpu')
        lora_state_dict = {
            k: v for k, v in checkpoint.items() 
            if k not in ['epoch', 'step', 'optimizer', 'scheduler']
        }
        self.model.model.llm.load_state_dict(lora_state_dict, strict=False)
        
        # 2. è©±è€…åŸ‹ã‚è¾¼ã¿ãƒ­ãƒ¼ãƒ‰
        spk2embedding = torch.load(embedding_path, map_location='cpu')
        
        # 3. â­ æ¬¡å…ƒå¤‰æ›ï¼ˆé‡è¦ï¼ï¼‰
        if isinstance(spk2embedding[speaker_id], list):
            embedding = torch.tensor(spk2embedding[speaker_id]).unsqueeze(0)
        else:
            embedding = spk2embedding[speaker_id]
            if embedding.dim() == 1:
                embedding = embedding.unsqueeze(0)  # [192] â†’ [1, 192]
        
        # 4. â­ ãƒ¢ãƒ‡ãƒ«ã«ç™»éŒ²
        self.model.frontend.spk2info[speaker_id] = {'embedding': embedding}
        
        # 5. ã‚­ãƒ£ãƒƒã‚·ãƒ¥ä¿å­˜
        self._lora_cache[speaker_id] = lora_state_dict
        self._embedding_cache[speaker_id] = embedding
        
        return True
    
    def synthesize_sft(self, text: str, speaker: str, speed: float = 1.0):
        """éã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°éŸ³å£°åˆæˆ"""
        self.load_speaker_lora(speaker)
        result = list(self.model.inference_sft(text, speaker, stream=False, speed=speed))
        audio = torch.cat([chunk['tts_speech'] for chunk in result], dim=1)
        return audio
    
    def stream_sft_pcm(self, text: str, speaker: str, speed: float = 1.0):
        """ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°éŸ³å£°åˆæˆï¼ˆPCMå½¢å¼ï¼‰"""
        self.load_speaker_lora(speaker)
        for chunk in self.model.inference_sft(text, speaker, stream=True, speed=speed):
            if 'tts_speech' in chunk:
                audio_np = chunk['tts_speech'].squeeze(0).cpu().numpy()
                audio_int16 = (audio_np * 32767).astype('int16')
                yield audio_int16.tobytes()
```

### `speaker_config.json` è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«

**ãƒ•ã‚¡ã‚¤ãƒ«**: `/mnt/c/Users/fhoshina/development/CosyVoice/api_server/speaker_config.json`

```json
{
  "speakers": {
    "yotaro": {
      "type": "lora",
      "lora_model_path": "/mnt/c/Users/fhoshina/development/CosyVoice/lora_yotaro_trained/epoch_12_whole.pt",
      "spk_embedding_path": "/mnt/c/Users/fhoshina/development/CosyVoice/lora_yotaro/spk2embedding.pt",
      "description": "Yotaro voice (Epoch 12, Acc 93.0%)",
      "active": true
    }
  },
  "default_speaker": "yotaro"
}
```

### `tts_server.py` WebSocketã‚µãƒ¼ãƒãƒ¼ï¼ˆWSLå´ï¼‰

**ãƒ•ã‚¡ã‚¤ãƒ«**: `/mnt/c/Users/fhoshina/development/CosyVoice/api_server/tts_server.py`

```python
import asyncio
import json
import websockets
from cosyvoice_engine import CosyVoiceEngine

tts_engine: CosyVoiceEngine | None = None

async def websocket_handler(ws):
    await ws.send(json.dumps({
        "status": "connected",
        "message": "TTS Server Ready (Multi-Speaker LoRA Support)"
    }))
    
    async for message in ws:
        req = json.loads(message)
        text = req.get("text")
        speaker = req.get("speaker", "yotaro")
        stream = req.get("stream", False)
        
        if stream:
            # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°
            await ws.send(json.dumps({
                "status": "start",
                "stream": True,
                "format": "pcm_s16le",
                "channels": 1,
                "sample_rate": 24000
            }))
            
            for pcm_chunk in tts_engine.stream_sft_pcm(text, speaker):
                await ws.send(pcm_chunk)  # ãƒã‚¤ãƒŠãƒªPCMé€ä¿¡
            
            await ws.send(json.dumps({"status": "done"}))

async def main():
    global tts_engine
    tts_engine = CosyVoiceEngine()
    
    async with websockets.serve(websocket_handler, "0.0.0.0", 8002):
        await asyncio.Future()

if __name__ == "__main__":
    asyncio.run(main())
```

### `controller.py` ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆï¼ˆMacå´ï¼‰

**ãƒ•ã‚¡ã‚¤ãƒ«**: `~/development/PresidentClone/controller.py`

```python
async def _infer_and_play_tts(full_text: str):
    """TTSã‚µãƒ¼ãƒãƒ¼ã«æ¥ç¶šã—ã¦éŸ³å£°ã‚’å†ç”Ÿ"""
    async with websockets.connect(MOUTH_TTS_SERVER_URL) as ws:
        # æ¥ç¶šç¢ºèª
        connect_msg = await ws.recv()
        
        # ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡
        request = {
            "text": full_text,
            "mode": "sft",           # â­ LoRAä½¿ç”¨æ™‚ã¯sftãƒ¢ãƒ¼ãƒ‰
            "speaker": "yotaro",     # â­ LoRAå­¦ç¿’ã—ãŸè©±è€…ID
            "stream": True
        }
        await ws.send(json.dumps(request))
        
        # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å—ä¿¡ & å†ç”Ÿ
        audio_chunks = []
        while True:
            message = await ws.recv()
            
            # JSONãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
            if isinstance(message, str):
                response = json.loads(message)
                if response.get("status") == "done":
                    break
            
            # ãƒã‚¤ãƒŠãƒªPCMãƒ‡ãƒ¼ã‚¿
            elif isinstance(message, bytes):
                # â­ ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å†ç”Ÿ
                audio_stream.write(message)
                audio_chunks.append(message)
        
        # ä¿å­˜ç”¨
        if audio_chunks:
            all_audio = b''.join(audio_chunks)
            save_audio_result(all_audio)
```

---

## ã‚·ã‚¹ãƒ†ãƒ æ§‹æˆ

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               Macå´ (Client)                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚         controller.py                      â”‚  â”‚
â”‚  â”‚  - WebSocket Client                        â”‚  â”‚
â”‚  â”‚  - PyAudio éŸ³å£°å†ç”Ÿ                        â”‚  â”‚
â”‚  â”‚  - speaker="yotaro" æŒ‡å®š                   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚ WebSocket (ws://100.64.94.124:8002)
                     â”‚ {"text": "...", "mode": "sft", "speaker": "yotaro"}
                     â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          WSL/Linuxå´ (Server)                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚         tts_server.py                      â”‚  â”‚
â”‚  â”‚  - WebSocket Server (port 8002)           â”‚  â”‚
â”‚  â”‚  - ãƒªã‚¯ã‚¨ã‚¹ãƒˆå—ä¿¡ â†’ CosyVoiceEngineå‘¼å‡º   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                    â†“                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚      cosyvoice_engine.py                  â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚ load_speaker_lora("yotaro")         â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  1. LoRAé‡ã¿ãƒ­ãƒ¼ãƒ‰ (epoch_12.pt)    â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  2. åŸ‹ã‚è¾¼ã¿ãƒ­ãƒ¼ãƒ‰ (spk2embedding.pt)â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  3. Tensorå¤‰æ› [192]â†’[1,192]        â”‚  â”‚  â”‚
â”‚  â”‚  â”‚  4. spk2info['yotaro']ã«ç™»éŒ²        â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚  â”‚ synthesize_sft(text, "yotaro")      â”‚  â”‚  â”‚
â”‚  â”‚  â”‚   â†’ model.inference_sft()            â”‚  â”‚  â”‚
â”‚  â”‚  â”‚   â†’ PCMã‚¹ãƒˆãƒªãƒ¼ãƒ ç”Ÿæˆ                â”‚  â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                  â”‚
â”‚  ãƒ•ã‚¡ã‚¤ãƒ«æ§‹æˆ:                                   â”‚
â”‚  /mnt/c/Users/.../CosyVoice/                    â”‚
â”‚  â”œâ”€â”€ api_server/                                â”‚
â”‚  â”‚   â”œâ”€â”€ cosyvoice_engine.py                   â”‚
â”‚  â”‚   â”œâ”€â”€ tts_server.py                         â”‚
â”‚  â”‚   â””â”€â”€ speaker_config.json                   â”‚
â”‚  â”œâ”€â”€ lora_yotaro/                               â”‚
â”‚  â”‚   â””â”€â”€ spk2embedding.pt  â† è©±è€…åŸ‹ã‚è¾¼ã¿      â”‚
â”‚  â””â”€â”€ lora_yotaro_trained/                       â”‚
â”‚      â””â”€â”€ epoch_12_whole.pt  â† LoRAé‡ã¿         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### 1. `KeyError: 'yotaro'` ãŒç™ºç”Ÿã™ã‚‹

**åŸå› **: `spk2info` ã«è©±è€…IDãŒç™»éŒ²ã•ã‚Œã¦ã„ãªã„

**è§£æ±ºç­–**:
```python
# ç¢ºèª
print(model.frontend.spk2info.keys())  # 'yotaro' ãŒå«ã¾ã‚Œã¦ã„ã‚‹ã‹ï¼Ÿ

# ç™»éŒ²ã•ã‚Œã¦ã„ãªã„å ´åˆ
embedding = torch.tensor(spk2embedding['yotaro']).unsqueeze(0)
model.frontend.spk2info['yotaro'] = {'embedding': embedding}
```

### 2. `IndexError: Dimension out of range`

**åŸå› **: åŸ‹ã‚è¾¼ã¿ãŒ1æ¬¡å…ƒ `[192]` ã®ã¾ã¾

**è§£æ±ºç­–**:
```python
# NG: 1æ¬¡å…ƒ
embedding = torch.tensor(spk2embedding['yotaro'])  # [192]

# OK: 2æ¬¡å…ƒ
embedding = torch.tensor(spk2embedding['yotaro']).unsqueeze(0)  # [1, 192]
```

### 3. éŸ³å£°ãŒå†ç”Ÿã•ã‚Œãªã„

**åŸå› **: WebSocketã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸å½¢å¼ãŒä¸ä¸€è‡´

**ç¢ºèªãƒã‚¤ãƒ³ãƒˆ**:
- ã‚µãƒ¼ãƒãƒ¼å´: ãƒã‚¤ãƒŠãƒªPCMã‚’ç›´æ¥é€ä¿¡ `await ws.send(pcm_bytes)`
- ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆå´: `isinstance(message, bytes)` ã§åˆ¤å®šã—ã¦å—ä¿¡

### 4. `ModuleNotFoundError: No module named 'cosyvoice'`

**åŸå› **: PYTHONPATHãŒè¨­å®šã•ã‚Œã¦ã„ãªã„

**è§£æ±ºç­–**:
```bash
export PYTHONPATH="/mnt/c/Users/fhoshina/development/CosyVoice:${PYTHONPATH}"
python tts_server.py
```

### 5. ãƒ¡ãƒ¢ãƒªä¸è¶³ï¼ˆOOM Killerï¼‰

**åŸå› **: WSLã®ãƒ¡ãƒ¢ãƒªåˆ¶é™

**è§£æ±ºç­–**: `.wslconfig` ã§16GBä»¥ä¸Šã«è¨­å®š
```ini
[wsl2]
memory=16GB
```

---

## ã‚­ãƒ¼ãƒã‚¤ãƒ³ãƒˆã¾ã¨ã‚

| é …ç›® | é‡è¦ãƒã‚¤ãƒ³ãƒˆ |
|------|------------|
| **LoRAé‡ã¿** | `epoch_12_whole.pt` ã‚’ãƒ­ãƒ¼ãƒ‰ â†’ `model.model.llm.load_state_dict()` |
| **è©±è€…åŸ‹ã‚è¾¼ã¿** | `spk2embedding.pt` ã‹ã‚‰å–å¾— â†’ **å¿…ãš2æ¬¡å…ƒ** `[1, 192]` ã«å¤‰æ› |
| **ãƒ¢ãƒ‡ãƒ«ç™»éŒ²** | `model.frontend.spk2info[speaker_id] = {'embedding': emb}` |
| **æ¨è«–** | `model.inference_sft(text, speaker_id)` ã§éŸ³å£°åˆæˆ |
| **ã‚­ãƒ£ãƒƒã‚·ãƒ¥** | 2å›ç›®ä»¥é™ã¯ `_lora_cache` ã‹ã‚‰é«˜é€Ÿãƒ­ãƒ¼ãƒ‰ |
| **é€šä¿¡å½¢å¼** | WebSocketã§ãƒã‚¤ãƒŠãƒªPCMã‚’ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°é€ä¿¡ |

---

## å‚è€ƒæƒ…å ±

- **CosyVoice2 GitHub**: https://github.com/FunAudioLLM/CosyVoice
- **å­¦ç¿’ãƒ‡ãƒ¼ã‚¿**: 298ã‚µãƒ³ãƒ—ãƒ«ï¼ˆæ¨å¥¨: 500-1000ã‚µãƒ³ãƒ—ãƒ«ï¼‰
- **å­¦ç¿’ã‚¨ãƒãƒƒã‚¯**: Epoch 12, Accuracy 93.0%
- **éŸ³å£°å½¢å¼**: PCM s16le, 24kHz, ãƒ¢ãƒãƒ©ãƒ«
- **RTF (Real-Time Factor)**: ~1.0 (ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç”Ÿæˆ)

---

## ã¾ã¨ã‚

**æˆåŠŸã®éµ**ã¯ä»¥ä¸‹ã®3ç‚¹:

1. âœ… **LoRAé‡ã¿ã®æ­£ã—ã„ãƒ­ãƒ¼ãƒ‰**: ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’é™¤å¤–ã—ã¦LLMã«é©ç”¨
2. âœ… **è©±è€…åŸ‹ã‚è¾¼ã¿ã®æ¬¡å…ƒå¤‰æ›**: `[192]` â†’ `[1, 192]` (ãƒãƒƒãƒæ¬¡å…ƒè¿½åŠ )
3. âœ… **spk2infoã¸ã®ç™»éŒ²**: ãƒ¢ãƒ‡ãƒ«ãŒè©±è€…IDã‚’èªè­˜ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹

ã“ã‚Œã«ã‚ˆã‚Šã€`controller.py` ã‹ã‚‰ `speaker="yotaro"` ã‚’æŒ‡å®šã™ã‚‹ã ã‘ã§ã€LoRAã§å­¦ç¿’ã—ãŸå£°ã§éŸ³å£°åˆæˆãŒã§ãã‚‹ã‚ˆã†ã«ãªã‚Šã¾ã—ãŸï¼

---

**ä½œæˆæ—¥**: 2025-11-17  
**ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ**: PresidentClone  
**å®Ÿè£…è€…**: GitHub Copilot + User
